# Elevate_Labs_Task-1
*Data cleaning and Handling*
# Titanic Dataset Preprocessing

This repository contains the data cleaning and preprocessing workflow applied to the Titanic dataset, implemented using Google Colab. The notebook demonstrates essential steps to prepare raw data for machine learning.

## Overview

The Titanic dataset is a common benchmark for predictive modeling. To build effective machine learning models, raw data must be cleaned and transformed. This project covers key preprocessing tasks, including:

- Handling missing values through imputation or removal  
- Encoding categorical features into numerical values  
- Scaling numerical features for improved model performance  
- Removing irrelevant columns  
- Splitting data into training and testing sets for evaluation  

## Project Contents

- `Titanic_Preprocessing.ipynb` â€” Google Colab notebook illustrating the entire preprocessing pipeline  

## Usage

Open the notebook in Google Colab and run each cell to execute the preprocessing steps. The final output is a cleaned dataset ready for machine learning modeling.

## Requirements

- Google Colab (no local setup required)  
- Python libraries: pandas, scikit-learn (pre-installed in Colab)

## Contact

Feel free to open an issue or contact me for any questions or feedback.

---


---

